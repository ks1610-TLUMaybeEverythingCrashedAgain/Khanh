from ultralytics import YOLO
import cv2
import numpy as np
import matplotlib.pyplot as plt

def find_scale(size):
    size = int(size * 0.2)
    if size < 32:
        size = 32

    if size % 32 == 0:
        return size

    return ((size // 32) + 1) * 32

# --- C·∫§U H√åNH ---
MODEL_PATH = r'best.pt'
IMAGE_PATH = r'test.jpg' #thay ƒë∆∞·ªùng d·∫´n
CONFIDENCE_THRESHOLD = 0.4  
whsize = find_scale(max(cv2.imread(IMAGE_PATH).shape[:2]))
SLICE_SIZE = whsize         
OVERLAP_RATIO = 0.25        

# --- 1. H√ÄM TI·ªÄN X·ª¨ L√ù ·∫¢NH (Pre-processing) ---
def preprocess_image(image):
    """
    S·ª≠ d·ª•ng CLAHE ƒë·ªÉ c√¢n b·∫±ng s√°ng c·ª•c b·ªô, gi√∫p linh ki·ªán n·ªïi b·∫≠t h∆°n tr√™n n·ªÅn m·∫°ch.
    """
    # Chuy·ªÉn sang h·ªá m√†u LAB
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    
    # √Åp d·ª•ng CLAHE l√™n k√™nh L (Lightness)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    
    # G·ªôp l·∫°i v√† chuy·ªÉn v·ªÅ BGR
    limg = cv2.merge((cl, a, b))
    final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)
    return final

# --- 2. H√ÄM NH·∫¨N DI·ªÜN C·∫ÆT L√ÅT (Tiled Inference) ---
def predict_tiled(model, source_img, tile_size=640, overlap=0.25, conf=0.5):
    img_h, img_w = source_img.shape[:2]
    
    # T√≠nh b∆∞·ªõc nh·∫£y (stride) d·ª±a tr√™n overlap
    stride = int(tile_size * (1 - overlap))
    
    all_boxes = []
    all_scores = []
    all_class_ids = []

    print(f"üîÑ ƒêang x·ª≠ l√Ω ·∫£nh k√≠ch th∆∞·ªõc {img_w}x{img_h} v·ªõi √¥ c·∫Øt {tile_size}x{tile_size}...")

    # Duy·ªát qua t·ª´ng √¥ c·ªßa ·∫£nh
    for y in range(0, img_h, stride):
        for x in range(0, img_w, stride):
            # X√°c ƒë·ªãnh t·ªça ƒë·ªô c·∫Øt, ƒë·∫£m b·∫£o kh√¥ng v∆∞·ª£t qu√° k√≠ch th∆∞·ªõc ·∫£nh
            x_end = min(x + tile_size, img_w)
            y_end = min(y + tile_size, img_h)
            x_start = x_end - tile_size if x_end - tile_size > 0 else 0
            y_start = y_end - tile_size if y_end - tile_size > 0 else 0

            # C·∫Øt ·∫£nh
            tile = source_img[y_start:y_end, x_start:x_end]

            # Nh·∫≠n di·ªán tr√™n t·ª´ng √¥ nh·ªè
            results = model.predict(tile, conf=conf, verbose=False)
            
            # X·ª≠ l√Ω k·∫øt qu·∫£
            for r in results:
                boxes = r.boxes
                for box in boxes:
                    # L·∫•y t·ªça ƒë·ªô t∆∞∆°ng ƒë·ªëi trong √¥ (x1, y1, x2, y2)
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    
                    # Chuy·ªÉn ƒë·ªïi sang t·ªça ƒë·ªô to√†n c·ª•c c·ªßa ·∫£nh g·ªëc
                    global_x1 = int(x1 + x_start)
                    global_y1 = int(y1 + y_start)
                    global_x2 = int(x2 + x_start)
                    global_y2 = int(y2 + y_start)
                    
                    all_boxes.append([global_x1, global_y1, global_x2 - global_x1, global_y2 - global_y1]) # Format cho NMS: [x, y, w, h]
                    all_scores.append(float(box.conf[0]))
                    all_class_ids.append(int(box.cls[0]))

    return all_boxes, all_scores, all_class_ids

# --- 3. H√ÄM MAIN ---
def detect_and_highlight():
    try:
        # 1. Load Model
        print(f"ƒêang t·∫£i model t·ª´: {MODEL_PATH}...")
        model = YOLO(MODEL_PATH)

        # 2. ƒê·ªçc ·∫£nh
        original_img = cv2.imread(IMAGE_PATH)
        if original_img is None:
            print("‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh!")
            return

        # 3. Ti·ªÅn x·ª≠ l√Ω ·∫£nh (L√†m n√©t, c√¢n b·∫±ng s√°ng)
        processed_img = preprocess_image(original_img)
        
        # 4. Ch·∫°y nh·∫≠n di·ªán theo ph∆∞∆°ng ph√°p c·∫Øt l√°t (Tiling)
        boxes, scores, class_ids = predict_tiled(
            model, 
            processed_img, 
            tile_size=SLICE_SIZE, 
            overlap=OVERLAP_RATIO, 
            conf=CONFIDENCE_THRESHOLD
        )

        # 5. √Åp d·ª•ng Non-Maximum Suppression (NMS) ƒë·ªÉ lo·∫°i b·ªè c√°c khung tr√πng nhau do c·∫Øt ch·ªìng l·∫•n
        # 0.4 l√† ng∆∞·ª°ng giao nhau (IOU threshold)
        indices = cv2.dnn.NMSBoxes(boxes, scores, score_threshold=CONFIDENCE_THRESHOLD, nms_threshold=0.4)

        print(f"‚úÖ ƒê√£ t√¨m th·∫•y {len(indices)} linh ki·ªán sau khi g·ªôp k·∫øt qu·∫£.")

        # 6. V·∫Ω k·∫øt qu·∫£ l√™n ·∫£nh g·ªëc
        for i in indices:
            # cv2.dnn.NMSBoxes tr·∫£ v·ªÅ index d·∫°ng list ho·∫∑c m·∫£ng con, c·∫ßn x·ª≠ l√Ω ƒë·ªÉ l·∫•y int
            idx = i if isinstance(i, (int, np.integer)) else i[0]
            
            x, y, w, h = boxes[idx]
            label = str(model.names[class_ids[idx]])
            score = scores[idx]

            # V·∫Ω khung ch·ªØ nh·∫≠t
            cv2.rectangle(original_img, (x, y), (x + w, y + h), (0, 255, 0), 2)
            
            # Vi·∫øt t√™n linh ki·ªán
            cv2.putText(original_img, f"{label} {score:.2f}", (x, y - 10), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            print(f"- {label}: {score:.2f}")

        # 7. Hi·ªÉn th·ªã k·∫øt qu·∫£
        # Resize ·∫£nh nh·ªè l·∫°i ƒë·ªÉ hi·ªÉn th·ªã v·ª´a m√†n h√¨nh n·∫øu ·∫£nh qu√° l·ªõn
        display_img = original_img.copy()
        h, w = display_img.shape[:2]
        if w > 1280:
            scale = 1280 / w
            display_img = cv2.resize(display_img, (1280, int(h * scale)))

        cv2.imshow("Ket qua Nhan dien Nang cao (Tiled)", display_img)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        
        # L∆∞u ·∫£nh full HD
        cv2.imwrite("ket_qua.jpg", original_img)
        print("üíæ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£ th√†nh 'ket_qua_pcb_tiled.jpg'")

    except Exception as e:
        print(f"‚ùå C√≥ l·ªói x·∫£y ra: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    detect_and_highlight()